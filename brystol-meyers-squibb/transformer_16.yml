# optimization
lr: 0.0003
optimizer: "Adam"
batch_size: 128
gradient_clip_val: 1.0
# scheduler:
#   CosineAnnealingLR:
#     T_max: 10
#     eta_min: 0.00001
#     verbose: True
# data
num_workers: 24
pin_memory: True
subset: 0.4
# model
img_size: 128
patch_size: 16
embed_dim: 256
nhead: 4
num_encoder_layers: 12
num_decoder_layers: 12
dropout: 0.
max_len: 277
load_from: False
# data augmentation
train_trans:
  Resize:
    width: 128
    height: 128
val_trans:
  Resize:
    width: 128
    height: 128
# training params
gpus: 1
precision: 16
max_epochs: 10
# debugging options
train_batches: 1.
shuffle_train: True
val_batches: 1.
val_with_train: False
log: True
