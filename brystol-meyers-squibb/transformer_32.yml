# optimization
lr: 0.0003
optimizer: "Adam"
batch_size: 128
gradient_clip_val: 1.0
scheduler:
  CosineAnnealingLR:
    T_max: 10
    eta_min: 0.00001
    verbose: True
# data
num_workers: 24
pin_memory: True
subset: 0.1
# model
img_size: 128
patch_size: 32
embed_dim: 1024
nhead: 16
num_encoder_layers: 24
num_decoder_layers: 24
dropout: 0.1
max_len: 21
load_from: False
# data augmentation
train_trans:
  Resize:
    width: 128
    height: 128
val_trans:
  Resize:
    width: 128
    height: 128
# training params
gpus: 1
precision: 16
max_epochs: 10
# debugging options
train_batches: 1.
shuffle_train: True
val_batches: 1.
val_with_train: False
log: True
